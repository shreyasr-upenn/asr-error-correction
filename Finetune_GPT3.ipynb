{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetune GPT3",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyasr-upenn/asr-error-correction-cis522/blob/main/Finetune_GPT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIS 522 - Final Project\n",
        "### Team: Transcriptionists\n",
        "Members:\n",
        "Manni Arora - manni@seas.upenn.edu\n",
        "Pooja Dattatri - poojadat@seas.upenn.edu\n",
        "Shreyas Ramesh - shreyasr@seas.upenn.edu"
      ],
      "metadata": {
        "id": "0qACJe0MfJMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies\n"
      ],
      "metadata": {
        "id": "vArb0rRhsYYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!pip install openai\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6F6UA8HrxSq",
        "outputId": "3249453b-8b9a-47a2-d5e4-1cb006dd002a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.10-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 996 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=caac3265bd39127e09059d0f00ac5f923fb0449e69b5d02902dc75ba54be30b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.10 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.15\n",
            "Collecting openai\n",
            "  Downloading openai-0.18.1.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 837 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.58-py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.18.1-py3-none-any.whl size=53168 sha256=e88b0e0134862a6792c3e15a574a01e06b91fea40c500911e6e8512946810560\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/bf/24/fcdc9d2b81f9c7e565bb2036ec9f7cc930056b829895b3bf48\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.18.1 pandas-stubs-1.2.0.58\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting python-Levenshtein==0.12.2\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149863 sha256=7f3e944563831abe2a29f839e9f1bea801d6bf87c39794865073c69916e91a67\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "import openai\n",
        "import random\n",
        "from jiwer import wer\n",
        "openai.api_key = \"\"\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ],
      "metadata": {
        "id": "_VvNvPF8rqBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXlTRj6TxUrj",
        "outputId": "33350863-76bd-48df-f5e1-91493256f21d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare training data"
      ],
      "metadata": {
        "id": "aWK4_zNashCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/Shareddrives/CIS522Project/Data/output_ami_pretrained/fine_tune_data.jsonl') as f:\n",
        "  content = f.readlines()\n",
        "  random.shuffle(content)\n",
        "  file_lst = open('train.jsonl', 'w+')\n",
        "  for i in range(0, len(content)):\n",
        "    file_lst.write(content[i])\n",
        "  file_lst.close()"
      ],
      "metadata": {
        "id": "sO-q_D3WaDMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jsonl_filename = 'train.jsonl'"
      ],
      "metadata": {
        "id": "7dhvaRfPxfo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head '{jsonl_filename}'\n",
        "!wc -lw '{jsonl_filename}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GPCduBusAgO",
        "outputId": "883f37ff-77ac-4256-d401-cea6439a6e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"prompt\": \"ASR output: okay\\n\", \"completion\": \"ASR correction: okay\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: okay\\n\", \"completion\": \"ASR correction: okay\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: co\\n\", \"completion\": \"ASR correction: cool\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: yeah\\n\", \"completion\": \"ASR correction: yeah\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: oh okay oka kay\\n\", \"completion\": \"ASR correction: oh okay okay okay\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: so i think maybe we can agree on on a lounge in a separate room if we can manage to to find space elsewhere\\n\", \"completion\": \"ASR correction: okay so i think maybe we can agree on on the lounge in a separate room if we can manage to to find space elsewhere\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: i think if we go with the um design plate thing we'll have to\\n\", \"completion\": \"ASR correction: i think if we go with the um design plate thing we'll have to\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: or is there no problem\\n\", \"completion\": \"ASR correction: or w is there no problem\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: i know it really did the the whole mango idea was great\\n\", \"completion\": \"ASR correction: i know i really did the the whole mango idea was great\\n###\\n\"}\n",
            "{\"prompt\": \"ASR output: and um we can make special features\\n\", \"completion\": \"ASR correction: and um we can make special features\\n###\\n\"}\n",
            "  10041  205826 train.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetune on OpenAI's GPT-3 babbage "
      ],
      "metadata": {
        "id": "n_aKPCM4s02C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t '{jsonl_filename}' -m babbage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejEWlp62otnb",
        "outputId": "285a213b-6d78-408b-c627-b3498f22b9ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/1.41M [00:00<?, ?it/s]\rUpload progress: 100% 1.41M/1.41M [00:00<00:00, 1.77Git/s]\n",
            "Uploaded file from train.jsonl: file-nugnFydaaa5fb2fG226xL9nz\n",
            "Created fine-tune: ft-jDD5OERU8Tz6GxKYEt8wLF64\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2022-04-20 21:59:03] Created fine-tune: ft-jDD5OERU8Tz6GxKYEt8wLF64\n",
            "[2022-04-20 21:59:21] Fine-tune costs $0.67\n",
            "[2022-04-20 21:59:22] Fine-tune enqueued. Queue number: 0\n",
            "[2022-04-20 21:59:27] Fine-tune started\n",
            "[2022-04-20 22:03:47] Completed epoch 1/4\n",
            "[2022-04-20 22:07:44] Completed epoch 2/4\n",
            "[2022-04-20 22:11:42] Completed epoch 3/4\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-jDD5OERU8Tz6GxKYEt8wLF64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-jDD5OERU8Tz6GxKYEt8wLF64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzqlALUXkOzQ",
        "outputId": "cbc2f6f0-28d7-4df9-bb5a-ab498e434d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2022-04-20 21:59:03] Created fine-tune: ft-jDD5OERU8Tz6GxKYEt8wLF64\n",
            "[2022-04-20 21:59:21] Fine-tune costs $0.67\n",
            "[2022-04-20 21:59:22] Fine-tune enqueued. Queue number: 0\n",
            "[2022-04-20 21:59:27] Fine-tune started\n",
            "[2022-04-20 22:03:47] Completed epoch 1/4\n",
            "[2022-04-20 22:07:44] Completed epoch 2/4\n",
            "[2022-04-20 22:11:42] Completed epoch 3/4\n",
            "[2022-04-20 22:15:41] Completed epoch 4/4\n",
            "[2022-04-20 22:15:59] Uploaded model: babbage:ft-cis-700-33-2022-04-20-22-15-58\n",
            "[2022-04-20 22:16:02] Uploaded result file: file-ZR674Wb6H4rX7vEUqbrPZHo2\n",
            "[2022-04-20 22:16:03] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m babbage:ft-cis-700-33-2022-04-20-22-15-58 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ],
      "metadata": {
        "id": "EkzmwKNdtEZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label(prompt, finetuned_model):\n",
        "  response = openai.Completion.create(\n",
        "      model=finetuned_model,\n",
        "      prompt=\"ASR output: {prompt}\\nASR correction: \".format(\n",
        "          prompt=prompt\n",
        "      ),\n",
        "      temperature=0.7,\n",
        "      max_tokens=64,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"###\"]\n",
        "      )\n",
        "  output =  response['choices'][0]['text']\n",
        "  return output"
      ],
      "metadata": {
        "id": "jWdzEPissYv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []\n",
        "import pandas as pd    \n",
        "\n",
        "with open('/content/drive/Shareddrives/CIS522Project/Data/output_ami_pretrained/test_data.jsonl') as f:\n",
        "    lines = f.readlines()\n",
        "    print(len(lines))\n",
        "    output = []\n",
        "    true_labels = []\n",
        "    for line in lines:\n",
        "      prompt = line.split('\", \"completion\": \"')[0].split(\"{\\\"prompt\\\": \\\"\")[1].replace('\"','')\n",
        "      completion = line.split('\", \"completion\": \"')[1][:-6]\n",
        "      if not completion:\n",
        "        continue\n",
        "      gpt3_label = get_label(prompt, 'babbage:ft-cis-700-33-2022-04-20-22-15-58')\n",
        "      if not gpt3_label:\n",
        "        continue\n",
        "      true_labels.append(completion.split(\"ASR correction: \")[1])\n",
        "      output.append(gpt3_label)\n",
        "      print(f'[ASR output] {prompt}')\n",
        "      print(f'[Suggested correction] {gpt3_label}')\n",
        "      print('~'*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31K5M_JAuyyN",
        "outputId": "b0fad787-0cde-48ea-81fe-aa44799820cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WER"
      ],
      "metadata": {
        "id": "cxmZqsqrR0gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(wer(output, true_labels)*100, 2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4KsJs_eEBGq",
        "outputId": "5205a976-bd2e-492c-9e5a-5f0a587dbdc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27.14 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NBMFTcDnESEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}